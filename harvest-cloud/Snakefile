CHR_nms= ['1','2','3','4','5','6','7','8','9','10','11','12','13','14','15','16','17','18','19','20','21','22']
sample_nms= ['moms', 'dads', 'fets']
cohort_nms= ['harvestm12', 'harvestm24', 'rotterdam1', 'rotterdam2', 'normentfeb', 'normentmay', 'normentjan', 'normentjun']

pheno_nms= ['allPTD', 'GAraw', 'GAnrm', 'postTerm']

include: 'scripts/effect_origin/Snakefile'
include: 'scripts/FINEMAP/Snakefile'
include: 'scripts/HLA/Snakefile'
include: 'scripts/LDSCORE/Snakefile'

rule all:
	'Collect all result files.'
	input:
		expand('/mnt/work2/pol/metaGWAS/FINEMAP/results/{pheno}.snp', pheno= pheno_nms),
		'/mnt/work2/pol/metaGWAS/processed_data/ids/autosomes_IDS.txt',
		expand('/mnt/work2/pol/metaGWAS/HLA/data/{cohort}.bgl.phased.vcf.gz', cohort= cohort_nms),
                '/mnt/work2/pol/metaGWAS/pheno/pheno_all.txt',
		expand('/mnt/work2/pol/metaGWAS/HLA/results/{pheno}.txt', pheno= pheno_nms),
		expand('/mnt/work2/pol/metaGWAS/HLA/plots/manhattan_{pheno}.pdf', pheno= pheno_nms),
#		'/mnt/work2/pol/metaGWAS/LDSCORE/data/MOBAGENETICS.bed',
#		'/mnt/work2/pol/metaGWAS/LDSCORE/ldscores/MOBAGENETICS.l2.ldscore.gz'
#		expand('/mnt/work2/pol/metaGWAS/processed_data/haplotypes/{haplo}_PREG_ID', haplo= ['h1', 'h2', 'h3', 'h4']),
#		'/mnt/work2/pol/metaGWAS/results/effect_origin.txt'

def selectUnrelated(input_kin, df, x):
	kin= pd.read_csv(input_kin, header= 0, sep= '\t')
	kin= kin.loc[kin.Kinship > 0.0884, :]
	kin= kin.loc[kin.ID1.isin(x.values)]
	kin= kin.loc[kin.ID2.isin(x.values)]
	kin= kin.loc[:, ['ID1','ID2','Kinship']]
	kin_temp= kin.copy()
	kin_temp.columns= ['ID2', 'ID1', 'Kinship']
	kin_temp= kin_temp.append(kin)
	kin_temp['n']= kin_temp.groupby('ID1')['ID1'].transform('count')
	kin_temp['nn']= kin_temp.groupby('ID2')['ID2'].transform('count')
	kin_temp.sort_values(by=['n', 'nn'], inplace= True)
	to_keep= list()
	for i in range(0, len(kin_temp.index)):
		if kin_temp.iloc[i, 0] in kin_temp.iloc[0:i, 1].values:
			kin_temp.iloc[i, 1]= "X"
		else:
			to_keep.append(kin_temp.iloc[i, 0])
	to_remove= [i for i in kin_temp.ID1 if i not in to_keep]
	to_remove= list(set(to_remove))
	remove= pd.DataFrame({'FID': to_remove})
	remove['IID']= remove.FID
	return remove

rule FID_IID:
	'Extract FID and IID from .fam file.'
	input:
                '/mnt/archive/HARVEST/delivery-fhi/data/genotyped/m12/m12-genotyped.fam',
                '/mnt/archive/HARVEST/delivery-fhi/data/genotyped/m24/m24-genotyped.fam',
                '/mnt/archive/ROTTERDAM1/delivery-fhi/data/genotyped/genotyped.fam',
                '/mnt/archive/ROTTERDAM2/delivery-fhi/data/genotyped/genotyped.fam',
                '/mnt/archive/NORMENT1/delivery-fhi/data/genotyped/feb18/genotyped.fam',
                '/mnt/archive/NORMENT1/delivery-fhi/data/genotyped/may16/genotyped.fam'
	output:
		temp('/mnt/work2/pol/metaGWAS/pheno/{cohort}_all_ids.txt')
	run:
		if 'harvestm12' == wildcards.cohort: parameter= {input[0]}
                if 'harvestm24' == wildcards.cohort: parameter= {input[1]}
                if 'rotterdam1' == wildcards.cohort: parameter= {input[2]}
                if 'rotterdam2' == wildcards.cohort: parameter= {input[3]}
                if 'normentfeb' == wildcards.cohort: parameter= {input[4]}
                if 'normentmay' == wildcards.cohort: parameter= {input[5]}
		shell('cut -f1,2 -d" " {parameter} > {output[0]}')

rule phenofile:
        'Merge all data necessary to create a phenotype file for spontaneous delivery and PROM.'
        input:
                '/mnt/work/pol/{cohort}/pheno/{cohort}_mfr.csv',
                '/mnt/work/pol/{cohort}/pheno/{cohort}_linkage.csv',
                '/mnt/work/pol/{cohort}/pheno/flag_list.txt',
                '/mnt/work/pol/{cohort}/pca/pca_exclude.txt',
		'/mnt/work2/pol/metaGWAS/pheno/{cohort}_all_ids.txt'
        output:
                temp('/mnt/work2/pol/metaGWAS/pheno/{cohort}/temp_pheno.txt'),
		'/mnt/work2/pol/metaGWAS/pheno/maternal_{cohort}_ids.txt'
        script:
                'scripts/pheno_file.R'

rule concat_phenos_PCA:
	'Concat pheno files, and add PCA.'
	input:
		'/mnt/archive/MOBAGENETICS/genotypes-base/aux/pca/mobagen-total/mobagen-total-proj-pc',
		'/mnt/archive/MOBAGENETICS/genotypes-base/aux/pedigree/mobagen-ethnic-core-samples.kin0',
		expand('/mnt/work2/pol/metaGWAS/pheno/{cohort}/temp_pheno.txt', cohort= cohort_nms)
	output:
		'/mnt/work2/pol/metaGWAS/pheno/pheno_all.txt',
		'/mnt/work2/pol/metaGWAS/pheno/covars_all.txt'
	run:
		df_list= list()
		flist= [infile for infile in input if 'pheno' in infile]
		for infile in flist:
			x= pd.read_csv(infile, sep= '\t', header= 0)
			df_list.append(x)
		d= pd.concat(df_list)
		pca= pd.read_csv(input[0], header= 0, sep= '\t')
                remove= selectUnrelated(input[1], d, d.IID)
                d= d[~d.IID.isin(remove)]
                d= pd.merge(d, pca, how= 'left', on= 'IID')
                d.fillna('NA', inplace= True)
                d.to_csv(output[0], sep= '\t', header= True, index= False, columns= ['IID', 'allPTD', 'earlyPTD', 'postTerm', 'GAraw', 'GAnrm'])
                d.to_csv(output[1], sep= '\t', header= True, index= False, columns= ['IID', 'PC1', 'PC2', 'PC3', 'PC4', 'PC5', 'PC6', 'PC7', 'PC8', 'PC9', 'PC10', 'cohort'])
