import pandas as pd
import numpy as np

CHR_nms= ['1','2','3','4','5','6','7','8','9','10','11','12','13','14','15','16','17','18','19','20','21','22', 'X']
sample_nms= ['moms', 'dads', 'fets']
cohort_nms= ['harvestm12', 'harvestm24', 'rotterdam1', 'rotterdam2', 'normentfeb', 'normentmay', 'normentjan', 'normentjun']

rule list_vcf_ids:
        'Obtain list of IID present in each chromosome.'
        input:
                '/mnt/archive/MOBAGENETICS/genotypes-base/imputed/all/vcf/{CHR}.vcf.gz'
        output:
                temp('/mnt/work2/pol/metaGWAS/effect_origin/aux/vcf_ids/temp/{CHR}-ids.txt')
        shell:
                'bcftools query -l {input[0]} > {output[0]}'

rule merge_vcf_ids:
        'Keep only IIDs present in all chromosomes.'
        input:
                expand('/mnt/work2/pol/metaGWAS/effect_origin/aux/vcf_ids/temp/{CHR}-ids.txt', CHR= CHR_nms)
        output:
                '/mnt/work2/pol/metaGWAS/effect_origin/aux/vcf_ids/allchr-ids.txt'
        run:
                df_list= list()
                for infile in input:
                        d= pd.read_csv(infile, header= None, names= ['IID'])
                        df_list.append(d)
                d= reduce(lambda x, y: pd.merge(x, y, on = 'IID', how = 'inner'), df_list)
                d.to_csv(output[0], sep= '\t', header= True, index= False)


rule list_trio_ids:
        'Make a list of trio IDs with genotype data.'
        input:
                '/mnt/work/pol/MOBAGENETICS/PREG_ID_to_IID.txt',
                '/mnt/archive/MOBAGENETICS/genotypes-base/aux/flaglist-merged/mobagen-flaglist-n99259.txt',
                '/mnt/work/pol/MOBAGENETICS/pca_out.txt',
                '/mnt/work2/pol/metaGWAS/effect_origin/aux/vcf_ids/allchr-ids.txt'
        output:
                '/mnt/work2/pol/metaGWAS/effect_origin/aux/ids/fets_toextract.txt',
                '/mnt/work2/pol/metaGWAS/effect_origin/aux/ids/moms_toextract.txt',
                '/mnt/work2/pol/metaGWAS/effect_origin/aux/ids/dads_toextract.txt',
                '/mnt/work2/pol/metaGWAS/effect_origin/aux/ids/parent_offspring_trios.txt'
        run:
                d= pd.read_csv(input[0], sep= '\t', header= None, names= ['PREG_ID', 'IID', 'BATCH', 'Role'])
                x= pd.read_csv(input[1], sep= '\t', header= 0)
                x= x.loc[x.genotypesOK== True, :]
                x= x.loc[x.phenoOK== True, :]
                d= d.loc[d.IID.isin(x.IID.values), :]
                x= [line.strip() for line in open(input[2], 'r')]
                d= d.loc[~d.IID.isin(x), :]
                d= d.loc[d.BATCH != 'TED', :]
                x= pd.read_csv(input[3], sep= '\t', header= 0)
                d= d.loc[d.IID.isin(x.IID.values), :]
                d.drop_duplicates(subset= ['PREG_ID', 'IID'], inplace= True, keep= 'first')
                x= d.groupby('PREG_ID').size().reset_index()
                x= x.loc[x.iloc[:, 1]== 3, :]
                d= d.loc[d.PREG_ID.isin(x.PREG_ID.values), :]
                x= d.groupby(['PREG_ID', 'Role']).size().reset_index()
                x= x.loc[x.iloc[:, 2]>1, :]
                d= d.loc[~d.PREG_ID.isin(x.PREG_ID.values), :]
                df= d.pivot(index= 'PREG_ID', columns= 'Role', values= 'IID').reset_index()
                fets= d.loc[d.Role== 'Child', :]
                fets.drop_duplicates('IID', inplace= True, keep= 'first')
                moms= d.loc[d.Role== 'Mother', :]
                moms.drop_duplicates('IID', inplace= True, keep= 'first')
                dads= d.loc[d.Role== 'Father', :]
                dads.drop_duplicates('IID', inplace= True, keep= 'first')
                fets.to_csv(output[0], columns= ['IID'], sep= '\t', header= False, index= False)
                moms.to_csv(output[1], columns= ['IID'], sep= '\t', header= False, index= False)
                dads.to_csv(output[2], columns= ['IID'], sep= '\t', header= False, index= False)
                df.to_csv(output[3], sep= '\t', header= True, index= False)


rule format_fetal_egg:
	''
	params:
		'http://mccarthy.well.ox.ac.uk/publications/2019/EggGestationalDuration_NatureCommunications/Fetal_gest_duration_NComms2019.txt.gz'
	output:
		'/mnt/work2/pol/metaGWAS/effect_origin/processed_data/fetal_ga.txt'
	run:
		d= pd.read_csv(params[0], header= 0, compression= 'gzip', sep= ' ')
		d['Effect']= np.where(d.Non_effect_allele> d.Effect_allele, -1 * d.Effect, d.Effect)
		d[['Effect_allele', 'Non_effect_allele']]= np.where(d.Non_effect_allele> d.Effect_allele, [d['Non_effect_allele'], d['Effect_allele']], [d['Effect_allele'], d['Non_effect_allele']])
		d['ID']= d.Chr.apply(str) + ':' + d.Pos.apply(str) + ':' + d.Non_effelct_allele + ':' + d.Effect_allele
		d= d[['ID', 'Effect', 'StdErr', 'P', 'N']]
		d.columns= ['ID', 'BETA_fet', 'SE_fet', 'pvalue_fet', 'N_fet']
		d.to_csv(output[0], sep= '\t', header= True, index= False)


rule extract_regions_haplotype:
	''
	input:
		'/mnt/work2/pol/metaGWAS/results/meta/Maternal_GWAMA_GAraw.txt.gz',
		'/mnt/work2/pol/metaGWAS/topregions/top_variants/GAraw.txt',
		'/mnt/work2/pol/metaGWAS/cojo/results/GAraw.jma'
	output:
		'/mnt/work2/pol/metaGWAS/effect_origin/single_variant/variants_to_extract.txt'
	run:
		d= pd.read_csv(input[0], header= 0, usecols= ['CHR', 'POS', 'EFF', 'REF', 'BETA', 'pvalue', 'ID'], sep= '\t', compression= 'gzip')
		d= d.loc[d.pvalue<5e-8, :]
                d['CHR']= d.CHR.apply(str)
                d['CHR']= np.where(d.CHR=='23', 'X', d.CHR)
		x= pd.read_csv(input[1], sep= '\t', header= 0)
		z= pd.read_csv(input[2], sep= '\t', header= 0)
		ids= x.ID.tolist() + z.SNP.tolist()
		d= d.loc[d.ID.isin(ids), :]
		d['ID']= d['ID'].str.replace('23:', 'X:')
		d.sort_values('pvalue', ascending= True, inplace= True)
		d= d.groupby(['CHR', 'POS']).head(1).reset_index(drop=True)
		d.sort_values(['CHR', 'POS'], ascending= True, inplace= True)
		df= d[['CHR', 'POS', 'POS']]
		df.to_csv(output[0], sep= '\t', header= False, index= False)

rule list_trio_ids_old:
	'Make a list of trio IDs with genotype data.'
	input:
		'/mnt/work/pol/MOBAGENETICS/PREG_ID_to_IID.txt',
		'/mnt/archive/MOBAGENETICS/genotypes-base/aux/flaglist-merged/mobagen-flaglist-n99259.txt',
		'/mnt/work/pol/MOBAGENETICS/pca_out.txt',
		'/mnt/work2/pol/metaGWAS/PGS/GA/raw_data/vcf_ids'
	output:
		'/mnt/work2/pol/metaGWAS/effect_origin/processed_data/fets_toextract.txt',
		'/mnt/work2/pol/metaGWAS/effect_origin/processed_data/moms_toextract.txt',
		'/mnt/work2/pol/metaGWAS/effect_origin/processed_data/dads_toextract.txt',
		'/mnt/work2/pol/metaGWAS/effect_origin/processed_data/parent_offspring_trios.txt'
	run:
		d= pd.read_csv(input[0], sep= '\t', header= None, names= ['PREG_ID', 'IID', 'BATCH', 'Role'])
		x= pd.read_csv(input[1], sep= '\t', header= 0)
                x= x.loc[x.genotypesOK== True, :]
                x= x.loc[x.phenoOK== True, :]
		d= d.loc[d.IID.isin(x.IID.values), :]
		x= [line.strip() for line in open(input[2], 'r')]
		d= d.loc[~d.IID.isin(x), :]
		d= d.loc[d.BATCH != 'TED', :]
		x= [line.strip() for line in open(input[3], 'r')]
		d= d.loc[d.IID.isin(x), :]
		d.drop_duplicates(subset= ['PREG_ID', 'IID'], inplace= True, keep= 'first')
		x= d.groupby('PREG_ID').size().reset_index()
		x= x.loc[x.iloc[:, 1]== 3, :]
		d= d.loc[d.PREG_ID.isin(x.PREG_ID.values), :]
		x= d.groupby(['PREG_ID', 'Role']).size().reset_index()
		x= x.loc[x.iloc[:, 2]>1, :]
		d= d.loc[~d.PREG_ID.isin(x.PREG_ID.values), :]
		df= d.pivot(index= 'PREG_ID', columns= 'Role', values= 'IID').reset_index()
		fets= d.loc[d.Role== 'Child', :]
		fets.drop_duplicates('IID', inplace= True, keep= 'first')
		moms= d.loc[d.Role== 'Mother', :]
		moms.drop_duplicates('IID', inplace= True, keep= 'first')
		dads= d.loc[d.Role== 'Father', :]
		dads.drop_duplicates('IID', inplace= True, keep= 'first')
		fets.to_csv(output[0], columns= ['IID'], sep= '\t', header= False, index= False)
		moms.to_csv(output[1], columns= ['IID'], sep= '\t', header= False, index= False)
		dads.to_csv(output[2], columns= ['IID'], sep= '\t', header= False, index= False)
		df.to_csv(output[3], sep= '\t', header= True, index= False)


rule get_GT:
        'Extract GT from VCF file for a subset of genetic variants. Use IDs from the haplotype PGS.'
        input:
                '/mnt/work2/pol/metaGWAS/effect_origin/single_variant/variants_to_extract.txt',
                '/mnt/work2/pol/metaGWAS/effect_origin/processed_data/{sample}_toextract.txt',
                '/mnt/archive/MOBAGENETICS/genotypes-base/imputed/all/vcf/{CHR}.vcf.gz'
        output:
                temp('/mnt/work2/pol/metaGWAS/effect_origin/single_variant/processed_data/GT/temp/{sample}_gt{CHR}')
        run:
                shell("bcftools query -S {input[1]} -R {input[0]} -f '%CHROM\t%POS\t%REF\t%ALT[\t%GT]\n' {input[2]} -o {output[0]}")

rule add_header_GT:
        'Add header to genotype files.'
        input:
                '/mnt/work2/pol/metaGWAS/effect_origin/processed_data/{sample}_toextract.txt',
                '/mnt/work2/pol/metaGWAS/effect_origin/single_variant/processed_data/GT/temp/{sample}_gt{CHR}'
        output:
                temp('/mnt/work2/pol/metaGWAS/effect_origin/single_variant/processed_data/GT/{sample}_GT{CHR}')
        run:
                cols= ['chr','pos','ref','eff'] + [line.strip() for line in open(input[0], 'r')]
                d= pd.read_csv(input[1], header= None, names= cols, sep= '\t')
                d.drop_duplicates(['chr', 'pos'], keep=False, inplace= True)
                d.to_csv(output[0], sep= '\t', header= True, index= False)

rule concat_GT_chr:
        'Collect GT from all CHR.'
        input:
                expand('/mnt/work2/pol/metaGWAS/effect_origin/single_variant/processed_data/GT/{{sample}}_GT{CHR}', CHR= CHR_nms)
        output:
                '/mnt/work2/pol/metaGWAS/effect_origin/single_variant/processed_data/GT/{sample}_GT.txt'
        shell:
                '''
                set +o pipefail;
                head -1 {input[0]} > {output[0]}
                cat {input} | grep -v 'chr' >> {output[0]}
                '''

rule get_allele_transmission:
        'Retrieve allele transmission from family trios (after phasing).'
        input:
                '/mnt/work2/pol/metaGWAS/effect_origin/single_variant/processed_data/GT/fets_GT.txt',
                '/mnt/work2/pol/metaGWAS/effect_origin/single_variant/processed_data/GT/moms_GT.txt',
                '/mnt/work2/pol/metaGWAS/effect_origin/processed_data/parent_offspring_trios.txt',
                '/mnt/work2/pol/metaGWAS/effect_origin/single_variant/processed_data/GT/dads_GT.txt'
        output:
                '/mnt/work2/pol/metaGWAS/effect_origin/single_variant/processed_data/haplotypes/h1_PREG_ID',
                '/mnt/work2/pol/metaGWAS/effect_origin/single_variant/processed_data/haplotypes/h2_PREG_ID',
                '/mnt/work2/pol/metaGWAS/effect_origin/single_variant/processed_data/haplotypes/h3_PREG_ID',
                '/mnt/work2/pol/metaGWAS/effect_origin/single_variant/processed_data/haplotypes/h4_PREG_ID'
        script:
                'allele_transmission.py'


rule haplotype_based_analysis:
	''
	input:
		'/mnt/work2/pol/metaGWAS/effect_origin/single_variant/processed_data/haplotypes/h1_PREG_ID',
                '/mnt/work2/pol/metaGWAS/effect_origin/single_variant/processed_data/haplotypes/h2_PREG_ID',
                '/mnt/work2/pol/metaGWAS/effect_origin/single_variant/processed_data/haplotypes/h3_PREG_ID',
                '/mnt/work2/pol/metaGWAS/effect_origin/single_variant/processed_data/haplotypes/h4_PREG_ID',
		'/mnt/work2/pol/metaGWAS/pheno/pheno_trio.txt'
	output:
		'/mnt/work2/pol/metaGWAS/effect_origin/results/MoBaGENETICS.txt'
	script:
		'linear_hypotheses.R'
