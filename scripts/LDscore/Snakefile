import csv
import numpy as np
import gzip
import math
import pandas as pd

pheno_nms= ['allPTD', 'postTerm', 'GAraw', 'GAnrm']

rule prepare_LD_score_meta:
        ''
        input:
                '/mnt/hdd/common/pol/metaGWAS/sumstats/META/Maternal_GWAMA_{pheno}.txt.gz',
		'/mnt/hdd/common/pol/references/longrange_LD.txt'
        output:
                temp('/mnt/hdd/common/pol/metaGWAS/LDscore/ldsc_{pheno}.txt')
        run:
                d= pd.read_csv(input[0], sep= '\t', header= 0, compression= 'gzip', usecols= ['RSID', 'CHR', 'POS', 'TOTALSAMPLESIZE', 'REF', 'EFF', 'BETA', 'SE', 'pvalue'])
                d.columns= ['CHR', 'POS', 'A1', 'A2', 'N', 'BETA', 'SE', 'pvalue', 'SNP']
                d.dropna(axis= 0, inplace= True)
		d['CHR']= d.CHR.apply(str)
		x= pd.read_csv(input[1], header= None, names= ['CHR', 'pos1', 'pos2', 'z'], sep= '\t')
		x['CHR']= x.CHR.apply(str)
		d= pd.merge(d, x, on= 'CHR', how= 'left')
		d= d.loc[((d.POS< d.pos1) | (d.POS>d.pos2)) | (d.pos1.isnull()), :]
		d= d.loc[~((d.CHR==6) & (d.POS >28477797) & (d.POS< 33448354)), :]
		d.drop_duplicates(['CHR', 'POS', 'A1', 'A2'], keep= 'first', inplace= True)
                d.to_csv(output[0], sep= '\t', header= True, index= False, columns= ['SNP', 'CHR', 'POS', 'N', 'A2', 'A1', 'BETA', 'SE', 'pvalue'])

rule munge_LDSC_meta:
        'Format sumstats according to LDSC.'
        input:
                '/mnt/hdd/common/pol/metaGWAS/LDscore/ldsc_{pheno}.txt'
        output:
                '/mnt/hdd/common/pol/metaGWAS/LDscore/{pheno}.txt.sumstats.gz'
        params:
                '/mnt/hdd/common/pol/metaGWAS/LDscore/{pheno}.txt'
        conda:
                '/home/pol/software/ldsc/environment.yml'
        shell:
                """
		set +eu
		source /home/pol/miniconda3/etc/profile.d/conda.sh
                conda activate ldsc
                python2 /home/pol/software/ldsc/munge_sumstats.py \
		--merge-alleles /home/pol/software/ldsc/w_hm3.snplist \
                --out {params[0]} \
                --sumstats {input[0]} \
		--chunksize 500000
                conda deactivate
		set -eu
                """

rule Genetic_correlation_meta:
	''
	input:
		'/mnt/hdd/common/pol/metaGWAS/LDscore/{pheno}.txt.sumstats.gz',
		expand('/mnt/hdd/common/pol/metaGWAS/LDscore/{pheno}.txt.sumstats.gz', pheno= pheno_nms)
	output:
		'/mnt/hdd/common/pol/metaGWAS/LDscore/{pheno}_rg.log'
#	conda:
#		'/home/pol/software/ldsc/environment.yml'
	run:
		allfiles= [infile for infile in input if wildcards.pheno not in infile]
		allfiles= ','.join(allfiles)
                outfile= input[0].replace('.txt.sumstats.gz', '_rg')
		infile= input[0]
                shell("""
                set +eu
		source /home/pol/miniconda3/etc/profile.d/conda.sh
		conda activate ldsc
                python2 /home/pol/software/ldsc/ldsc.py \
                --rg {infile},{allfiles} \
                --ref-ld-chr /home/pol/software/ldsc/eur_w_ld_chr/ \
                --w-ld-chr /home/pol/software/ldsc/eur_w_ld_chr/ \
		--out {outfile}
                conda deactivate
		set -eu
                """)


rule format_RG_meta:
	''
	input:
		'/mnt/hdd/common/pol/metaGWAS/LDscore/{pheno}_rg.log'
	output:
		'/mnt/hdd/common/pol/metaGWAS/LDscore/{pheno}_temp'
	run:
		with open(input[0], 'r') as f:
			x= f.readlines()
		x= x[x.index('Summary of Genetic Correlation Results\n')+1:-3]
		with open(output[0], 'w') as f:
			f.write(''.join(x))

rule partitioned_heritability:
	'LDSC partitioned heritability.'
	input:
		'/mnt/hdd/common/pol/metaGWAS/LDscore/{pheno}.txt.sumstats.gz'
	output:
		'/mnt/hdd/common/pol/metaGWAS/LDscore/part_h2/{pheno}.log',
		'/mnt/hdd/common/pol/metaGWAS/LDscore/part_h2/{pheno}.results'
	params:
		'/mnt/hdd/common/pol/metaGWAS/LDscore/part_h2/{pheno}'
	shell:
		'''
		set +eu
                source /home/pol/miniconda3/etc/profile.d/conda.sh
                conda activate ldsc
		python2 /home/pol/software/ldsc/ldsc.py \
		--h2 {input[0]}\
		--ref-ld-chr /home/pol/software/ldsc/baseline/baseline/baselineLD. \
		--w-ld-chr /home/pol/software/ldsc/baseline/weights_hm3_no_hla/weights.\
		--overlap-annot\
		--frqfile-chr /home/pol/software/ldsc/baseline/1000G_Phase3_frq/1000G.EUR.QC.\
		--out {params[0]}
		conda deactivate
                set -eu
		'''

rule partitioned_heritability_cell_type:
        'LDSC partitioned heritability by cell type.'
        input:
                '/mnt/hdd/common/pol/metaGWAS/LDscore/{pheno}.txt.sumstats.gz'
        output:
                '/mnt/hdd/common/pol/metaGWAS/LDscore/h2_cts/{cts}/{pheno}.log',
                '/mnt/hdd/common/pol/metaGWAS/LDscore/h2_cts/{cts}/{pheno}.cell_type_results.txt'
        params:
                '/mnt/hdd/common/pol/metaGWAS/LDscore/h2_cts/{cts}/{pheno}',
		'/home/pol/software/ldsc/cts/Multi_tissue_{cts}.ldcts'
        shell:
                '''
                set +eu
                source /home/pol/miniconda3/etc/profile.d/conda.sh
                conda activate ldsc
		cd /home/pol/software/ldsc/cts/
                python2 /home/pol/software/ldsc/ldsc.py \
                --h2-cts {input[0]}\
                --ref-ld-chr-cts {params[1]} \
                --w-ld-chr /home/pol/software/ldsc/baseline/weights_hm3_no_hla/weights.\
		--ref-ld-chr /home/pol/software/ldsc/baseline/baseline/baselineLD.\
                --out {params[0]}
                conda deactivate
                set -eu
                '''

rule prepare_LD_score_individual_cohorts:
        ''
        input:
                '/mnt/hdd/common/pol/metaGWAS/sumstats/GAraw/{big5}_GAraw.txt',
                '/mnt/hdd/common/pol/references/longrange_LD.txt',
		'/mnt/hdd/common/pol/metaGWAS/processed_data/dbSNP153.txt'
        output:
                temp('/mnt/hdd/common/pol/metaGWAS/LDscore/individual_cohorts/ldsc_{big5}.txt')
        run:
                d= pd.read_csv(input[0], sep= '\t', header= 0, usecols= ['SNP', 'CHR', 'POS', 'N', 'REF', 'EFF', 'BETA', 'SE', 'pvalue'])[['SNP', 'CHR', 'POS', 'N', 'REF', 'EFF', 'BETA', 'SE', 'pvalue']]
		d['SNP']= d.SNP.str.replace(':SNP', '')
		d['SNP']= d.SNP.str.replace(':INDEL', '')
		d['CHR']= d.CHR.apply(str)
                d.columns= ['ID', 'CHR', 'POS', 'N', 'A2', 'A1', 'BETA', 'SE', 'pvalue']
                d.dropna(axis= 0, inplace= True)
                d['CHR']= d.CHR.apply(str)
                x= pd.read_csv(input[1], header= None, names= ['CHR', 'pos1', 'pos2', 'z'], sep= '\t')
                x['CHR']= x.CHR.apply(str)
		z= pd.read_csv(input[2], header= 0, sep= '\t')
		z.columns= ['ID', 'SNP']
		d= pd.merge(d, z, on= 'ID')
                d= pd.merge(d, x, on= 'CHR', how= 'left')
                d= d.loc[((d.POS< d.pos1) | (d.POS>d.pos2)) | (d.pos1.isnull()), :]
                d= d.loc[~((d.CHR==6) & (d.POS >28477797) & (d.POS< 33448354)), :]
                d.drop_duplicates(['CHR', 'POS', 'A1', 'A2'], keep= 'first', inplace= True)
                d.to_csv(output[0], sep= '\t', header= True, index= False, columns= ['SNP', 'CHR', 'POS', 'N', 'A2', 'A1', 'BETA', 'SE', 'pvalue'])

rule munge_LDSC_individual_cohorts:
        'Format sumstats according to LDSC.'
        input:
                '/mnt/hdd/common/pol/metaGWAS/LDscore/individual_cohorts/ldsc_{big5}.txt'
        output:
                temp('/mnt/hdd/common/pol/metaGWAS/LDscore/individual_cohorts/{big5}.txt.sumstats.gz')
        params:
                '/mnt/hdd/common/pol/metaGWAS/LDscore/individual_cohorts/{big5}.txt'
        conda:
                '/home/pol/software/ldsc/environment.yml'
        shell:
                """
                set +eu
                source /home/pol/miniconda3/etc/profile.d/conda.sh
                conda activate ldsc
                python2 /home/pol/software/ldsc/munge_sumstats.py \
                --merge-alleles /home/pol/software/ldsc/w_hm3.snplist \
                --out {params[0]} \
                --sumstats {input[0]} \
                --chunksize 500000
                conda deactivate
                set -eu
                """
rule heritability_individual_cohorts:
	''
	input:
		'/mnt/hdd/common/pol/metaGWAS/LDscore/individual_cohorts/{big5}.txt.sumstats.gz'
	output:
		'/mnt/hdd/common/pol/metaGWAS/LDscore/individual_cohorts/h2/{big5}_h2.log'
	params:
		'/mnt/hdd/common/pol/metaGWAS/LDscore/individual_cohorts/h2/{big5}_h2'
#       conda:
#               '/home/pol/software/ldsc/environment.yml'
	shell:
                """
                set +eu
                source /home/pol/miniconda3/etc/profile.d/conda.sh
                conda activate ldsc
                python2 /home/pol/software/ldsc/ldsc.py \
                --h2 {input[0]} \
                --ref-ld-chr /home/pol/software/ldsc/eur_w_ld_chr/ \
                --w-ld-chr /home/pol/software/ldsc/eur_w_ld_chr/ \
                --out {params[0]}
                conda deactivate
                set -eu
                """

rule merge_h2_individual_cohorts:
	''
	input:
		expand('/mnt/hdd/common/pol/metaGWAS/LDscore/individual_cohorts/h2/{big5}_h2.log', big5= big5_nms)
	output:
		'/mnt/hdd/common/pol/metaGWAS/LDscore/individual_cohorts/h2/allcohorts.txt'
	run:
		df_list= list()
		for infile in input:
			with open(infile, 'r') as f:
				lines= [line.strip() for line in f if line.startswith('Total Observed')]
				h2= float(lines[0].split(' ')[4])
				se= float(lines[0].split('(')[1].replace(')', ''))
				cohort= infile.split('/')[9].replace('_h2.log', '')
				d= pd.DataFrame({'cohort': cohort, 'h2': h2, 'se': se}, index= [0])
				df_list.append(d)
		d= pd.concat(df_list)
		d.to_csv(output[0], sep= '\t', header= True, index= False)
