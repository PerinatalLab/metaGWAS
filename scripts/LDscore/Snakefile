import csv
import numpy as np
import gzip
import math
import pandas as pd

pheno_nms= ['allPTD', 'postTerm', 'GAraw', 'GAnrm']

rule prepare_LD_score_meta:
        ''
        input:
                '/mnt/hdd/common/pol/metaGWAS/sumstats/META/Maternal_GWAMA_{pheno}.txt.gz',
#		'/mnt/hdd/common/pol/references/longrange_LD.txt'
        output:
                temp('/mnt/hdd/common/pol/metaGWAS/LDscore/ldsc_{pheno}.txt')
	threads: 3
        run:
                d= pd.read_csv(input[0], sep= '\t', header= 0, compression= 'gzip', usecols= ['RSID', 'CHR', 'POS', 'TOTALSAMPLESIZE', 'REF', 'EFF', 'BETA', 'SE', 'pvalue'])
                d.columns= ['CHR', 'POS', 'A1', 'A2', 'N', 'BETA', 'SE', 'pvalue', 'SNP']
                d.dropna(axis= 0, inplace= True)
		d['CHR']= d.CHR.apply(str)
#		x= pd.read_csv(input[1], header= None, names= ['CHR', 'pos1', 'pos2', 'z'], sep= '\t')
#		x['CHR']= x.CHR.apply(str)
#		d= pd.merge(d, x, on= 'CHR', how= 'left')
#		d= d.loc[((d.POS< d.pos1) | (d.POS>d.pos2)) | (d.pos1.isnull()), :]
		d= d.loc[~((d.CHR==6) & (d.POS >28477797) & (d.POS< 33448354)), :]
		d.drop_duplicates(['CHR', 'POS', 'A1', 'A2'], keep= 'first', inplace= True)
                d.to_csv(output[0], sep= '\t', header= True, index= False, columns= ['SNP', 'CHR', 'POS', 'N', 'A2', 'A1', 'BETA', 'SE', 'pvalue'])

rule munge_LDSC_meta:
        'Format sumstats according to LDSC.'
        input:
                '/mnt/hdd/common/pol/metaGWAS/LDscore/ldsc_{pheno}.txt'
        output:
                '/mnt/hdd/common/pol/metaGWAS/LDscore/{pheno}.txt.sumstats.gz'
        params:
                '/mnt/hdd/common/pol/metaGWAS/LDscore/{pheno}.txt'
        conda:
                '/home/pol/software/ldsc/environment.yml'
        shell:
                """
		set +eu
		source /home/pol/miniconda3/etc/profile.d/conda.sh
                conda activate ldsc
                python2 /home/pol/software/ldsc/munge_sumstats.py \
		--merge-alleles /home/pol/software/ldsc/w_hm3.snplist \
                --out {params[0]} \
                --sumstats {input[0]} \
		--chunksize 500000
                conda deactivate
		set -eu
                """

rule Genetic_correlation_meta:
	''
	input:
		'/mnt/hdd/common/pol/metaGWAS/LDscore/{pheno}.txt.sumstats.gz',
		expand('/mnt/hdd/common/pol/metaGWAS/LDscore/{pheno}.txt.sumstats.gz', pheno= pheno_nms)
	output:
		'/mnt/hdd/common/pol/metaGWAS/LDscore/{pheno}_rg.log'
#	conda:
#		'/home/pol/software/ldsc/environment.yml'
	run:
		allfiles= [infile for infile in input if wildcards.pheno not in infile]
		allfiles= ','.join(allfiles)
                outfile= input[0].replace('.txt.sumstats.gz', '_rg')
		infile= input[0]
                shell("""
                set +eu
		source /home/pol/miniconda3/etc/profile.d/conda.sh
		conda activate ldsc
                python2 /home/pol/software/ldsc/ldsc.py \
                --rg {infile},{allfiles} \
                --ref-ld-chr /home/pol/software/ldsc/eur_w_ld_chr/ \
                --w-ld-chr /home/pol/software/ldsc/eur_w_ld_chr/ \
		--out {outfile}
                conda deactivate
		set -eu
                """)


rule format_RG_meta:
	''
	input:
		'/mnt/hdd/common/pol/metaGWAS/LDscore/{pheno}_rg.log'
	output:
		'/mnt/hdd/common/pol/metaGWAS/LDscore/{pheno}_temp'
	run:
		with open(input[0], 'r') as f:
			x= f.readlines()
		x= x[x.index('Summary of Genetic Correlation Results\n')+1:-3]
		with open(output[0], 'w') as f:
			f.write(''.join(x))

rule partitioned_heritability:
	'LDSC partitioned heritability.'
	input:
		'/mnt/hdd/common/pol/metaGWAS/LDscore/{pheno}.txt.sumstats.gz'
	output:
		'/mnt/hdd/common/pol/metaGWAS/LDscore/part_h2/{pheno}.log',
		'/mnt/hdd/common/pol/metaGWAS/LDscore/part_h2/{pheno}.results'
	params:
		'/mnt/hdd/common/pol/metaGWAS/LDscore/part_h2/{pheno}'
	shell:
		'''
		set +eu
                source /home/pol/miniconda3/etc/profile.d/conda.sh
                conda activate ldsc
		python2 /home/pol/software/ldsc/ldsc.py \
		--h2 {input[0]}\
		--ref-ld-chr /home/pol/software/ldsc/baseline/baseline/baselineLD. \
		--w-ld-chr /home/pol/software/ldsc/baseline/weights_hm3_no_hla/weights.\
		--overlap-annot\
		--frqfile-chr /home/pol/software/ldsc/baseline/1000G_Phase3_frq/1000G.EUR.QC.\
		--out {params[0]}
		conda deactivate
                set -eu
		'''

rule partitioned_heritability_cell_type:
        'LDSC partitioned heritability by cell type.'
        input:
                '/mnt/hdd/common/pol/metaGWAS/LDscore/{pheno}.txt.sumstats.gz'
        output:
                '/mnt/hdd/common/pol/metaGWAS/LDscore/h2_cts/{cts}/{pheno}.log',
                '/mnt/hdd/common/pol/metaGWAS/LDscore/h2_cts/{cts}/{pheno}.cell_type_results.txt'
        params:
                '/mnt/hdd/common/pol/metaGWAS/LDscore/h2_cts/{cts}/{pheno}',
		'/home/pol/software/ldsc/cts/Multi_tissue_{cts}.ldcts'
        shell:
                '''
                set +eu
                source /home/pol/miniconda3/etc/profile.d/conda.sh
                conda activate ldsc
		cd /home/pol/software/ldsc/cts/
                python2 /home/pol/software/ldsc/ldsc.py \
                --h2-cts {input[0]}\
                --ref-ld-chr-cts {params[1]} \
                --w-ld-chr /home/pol/software/ldsc/baseline/weights_hm3_no_hla/weights.\
		--ref-ld-chr /home/pol/software/ldsc/baseline/baseline/baselineLD.\
                --out {params[0]}
                conda deactivate
                set -eu
                '''

rule prepare_LD_score_individual_cohorts:
        ''
        input:
                '/mnt/hdd/common/pol/metaGWAS/sumstats/GAraw/filtered/{big5}.txt',
                '/mnt/hdd/common/pol/references/longrange_LD.txt',
		'/mnt/hdd/common/pol/metaGWAS/processed_data/dbSNP153.txt'
        output:
                temp('/mnt/hdd/common/pol/metaGWAS/LDscore/individual_cohorts/ldsc_{big5}.txt')
        
	threads: 5
	run:
                d= pd.read_csv(input[0], sep= '\t', header= 0, usecols= ['SNP', 'CHR', 'POS', 'N', 'REF', 'EFF', 'BETA', 'SE', 'pvalue'])[['SNP', 'CHR', 'POS', 'N', 'REF', 'EFF', 'BETA', 'SE', 'pvalue']]
		d['SNP']= d.SNP.str.replace(':SNP', '')
		d['SNP']= d.SNP.str.replace(':INDEL', '')
		d['CHR']= d.CHR.apply(str)
                d.columns= ['ID', 'CHR', 'POS', 'N', 'A2', 'A1', 'BETA', 'SE', 'pvalue']
                d.dropna(axis= 0, inplace= True)
                d['CHR']= d.CHR.apply(str)
 #               x= pd.read_csv(input[1], header= None, names= ['CHR', 'pos1', 'pos2', 'z'], sep= '\t')
 #               x['CHR']= x.CHR.apply(str)
		z= pd.read_csv(input[2], header= 0, sep= '\t')
		z.columns= ['ID', 'SNP']
		d= pd.merge(d, z, on= 'ID')
  #              d= pd.merge(d, x, on= 'CHR', how= 'left')
  #              d= d.loc[((d.POS< d.pos1) | (d.POS>d.pos2)) | (d.pos1.isnull()), :]
                d= d.loc[~((d.CHR==6) & (d.POS >28477797) & (d.POS< 33448354)), :]
                d.drop_duplicates(['CHR', 'POS', 'A1', 'A2'], keep= 'first', inplace= True)
                d.to_csv(output[0], sep= '\t', header= True, index= False, columns= ['SNP', 'CHR', 'POS', 'N', 'A2', 'A1', 'BETA', 'SE', 'pvalue'])

rule munge_LDSC_individual_cohorts:
        'Format sumstats according to LDSC.'
        input:
                '/mnt/hdd/common/pol/metaGWAS/LDscore/individual_cohorts/ldsc_{big5}.txt'
        output:
                temp('/mnt/hdd/common/pol/metaGWAS/LDscore/individual_cohorts/{big5}.txt.sumstats.gz')
        params:
                '/mnt/hdd/common/pol/metaGWAS/LDscore/individual_cohorts/{big5}.txt'
        conda:
                '/home/pol/software/ldsc/environment.yml'
        shell:
                """
                set +eu
                source /home/pol/miniconda3/etc/profile.d/conda.sh
                conda activate ldsc
                python2 /home/pol/software/ldsc/munge_sumstats.py \
                --merge-alleles /home/pol/software/ldsc/w_hm3.snplist \
                --out {params[0]} \
                --sumstats {input[0]} \
                --chunksize 500000
                conda deactivate
                set -eu
                """

rule heritability_individual_cohorts:
	''
	input:
		'/mnt/hdd/common/pol/metaGWAS/LDscore/individual_cohorts/{big5}.txt.sumstats.gz'
	output:
		'/mnt/hdd/common/pol/metaGWAS/LDscore/individual_cohorts/h2/{big5}_h2.log'
	params:
		'/mnt/hdd/common/pol/metaGWAS/LDscore/individual_cohorts/h2/{big5}_h2'
#       conda:
#               '/home/pol/software/ldsc/environment.yml'
	shell:
                """
                set +eu
                source /home/pol/miniconda3/etc/profile.d/conda.sh
                conda activate ldsc
                python2 /home/pol/software/ldsc/ldsc.py \
                --h2 {input[0]} \
                --ref-ld-chr /home/pol/software/ldsc/eur_w_ld_chr/ \
                --w-ld-chr /home/pol/software/ldsc/eur_w_ld_chr/ \
                --out {params[0]}
                conda deactivate
                set -eu
                """

rule merge_h2_individual_cohorts:
        ''
        input:
                expand('/mnt/hdd/common/pol/metaGWAS/LDscore/individual_cohorts/h2/{big5}_h2.log', big5= big5_nms)
        output:
                '/mnt/hdd/common/pol/metaGWAS/LDscore/individual_cohorts/h2/allcohorts.txt'
        run:
                df_list= list()
                for infile in input:
                        with open(infile, 'r') as f:
                                lines= [line.strip() for line in f if line.startswith('Total Observed')]
                                h2= float(lines[0].split(' ')[4])
                                se= float(lines[0].split('(')[1].replace(')', ''))
                                cohort= infile.split('/')[9].replace('_h2.log', '')
                                d= pd.DataFrame({'cohort': cohort, 'h2': h2, 'se': se}, index= [0])
                                df_list.append(d)
                d= pd.concat(df_list)
                d.to_csv(output[0], sep= '\t', header= True, index= False)


rule prepare_LD_score_individual_cohorts_allPTD:
        ''
        input:
                '/mnt/hdd/common/pol/metaGWAS/sumstats/allPTD/filtered/{big5_allPTD}.txt',
                '/mnt/hdd/common/pol/references/longrange_LD.txt',
                '/mnt/hdd/common/pol/metaGWAS/processed_data/dbSNP153.txt'
        output:
                temp('/mnt/hdd/common/pol/metaGWAS/LDscore/individual_cohorts/allPTD/{big5_allPTD}_allPTD.txt')
        threads: 5
	run:
                d= pd.read_csv(input[0], sep= '\t', header= 0, usecols= ['SNP', 'CHR', 'POS', 'N', 'REF', 'EFF', 'BETA', 'SE', 'pvalue'])[['SNP', 'CHR', 'POS', 'N', 'REF', 'EFF', 'BETA', 'SE', 'pvalue']]
                d['SNP']= d.SNP.str.replace(':SNP', '')
                d['SNP']= d.SNP.str.replace(':INDEL', '')
                d['CHR']= d.CHR.apply(str)
                d.columns= ['ID', 'CHR', 'POS', 'N', 'A2', 'A1', 'BETA', 'SE', 'pvalue']
                d.dropna(axis= 0, inplace= True)
                d['CHR']= d.CHR.apply(str)
#                x= pd.read_csv(input[1], header= None, names= ['CHR', 'pos1', 'pos2', 'z'], sep= '\t')
#                x['CHR']= x.CHR.apply(str)
                z= pd.read_csv(input[2], header= 0, sep= '\t')
                z.columns= ['ID', 'SNP']
                d= pd.merge(d, z, on= 'ID')
#                d= pd.merge(d, x, on= 'CHR', how= 'left')
#                d= d.loc[((d.POS< d.pos1) | (d.POS>d.pos2)) | (d.pos1.isnull()), :]
                d= d.loc[~((d.CHR==6) & (d.POS >28477797) & (d.POS< 33448354)), :]
                d.drop_duplicates(['CHR', 'POS', 'A1', 'A2'], keep= 'first', inplace= True)
                d.to_csv(output[0], sep= '\t', header= True, index= False, columns= ['SNP', 'CHR', 'POS', 'N', 'A2', 'A1', 'BETA', 'SE', 'pvalue'])

rule munge_LDSC_individual_cohorts_allPTD:
        'Format sumstats according to LDSC.'
        input:
                '/mnt/hdd/common/pol/metaGWAS/LDscore/individual_cohorts/allPTD/{big5_allPTD}_allPTD.txt'
        output:
                temp('/mnt/hdd/common/pol/metaGWAS/LDscore/individual_cohorts/allPTD/{big5_allPTD}_allPTD.txt.sumstats.gz')
        params:
                '/mnt/hdd/common/pol/metaGWAS/LDscore/individual_cohorts/allPTD/{big5_allPTD}_allPTD.txt'
        conda:
                '/home/pol/software/ldsc/environment.yml'
        shell:
                """
                set +eu
                source /home/pol/miniconda3/etc/profile.d/conda.sh
                conda activate ldsc
                python2 /home/pol/software/ldsc/munge_sumstats.py \
                --merge-alleles /home/pol/software/ldsc/w_hm3.snplist \
                --out {params[0]} \
                --sumstats {input[0]} \
                --chunksize 500000
                conda deactivate
                set -eu
                """
rule heritability_individual_cohorts_allPTD:
        ''
        input:
                '/mnt/hdd/common/pol/metaGWAS/LDscore/individual_cohorts/allPTD/{big5_allPTD}_allPTD.txt.sumstats.gz'
        output:
                '/mnt/hdd/common/pol/metaGWAS/LDscore/individual_cohorts/h2/allPTD/{big5_allPTD}_allPTD.log'
        params:
                '/mnt/hdd/common/pol/metaGWAS/LDscore/individual_cohorts/h2/allPTD/{big5_allPTD}_allPTD'
#       conda:
#               '/home/pol/software/ldsc/environment.yml'
        shell:
                """
                set +eu
                source /home/pol/miniconda3/etc/profile.d/conda.sh
                conda activate ldsc
                python2 /home/pol/software/ldsc/ldsc.py \
                --h2 {input[0]} \
                --ref-ld-chr /home/pol/software/ldsc/eur_w_ld_chr/ \
                --w-ld-chr /home/pol/software/ldsc/eur_w_ld_chr/ \
                --out {params[0]}
                conda deactivate
                set -eu
                """

rule merge_h2_individual_cohorts_allPTD:
	''
	input:
		expand('/mnt/hdd/common/pol/metaGWAS/LDscore/individual_cohorts/h2/allPTD/{big5_allPTD}_allPTD.log', big5_allPTD= big5_nms_allPTD)
	output:
		'/mnt/hdd/common/pol/metaGWAS/LDscore/individual_cohorts/h2/allPTD/allcohorts.txt'
	run:
		df_list= list()
		for infile in input:
			with open(infile, 'r') as f:
				lines= [line.strip() for line in f if line.startswith('Total Observed')]
				h2= float(lines[0].split(' ')[4])
				se= float(lines[0].split('(')[1].replace(')', ''))
				cohort= infile.split('/')[10].replace('_allPTD.log', '')
				d= pd.DataFrame({'cohort': cohort, 'h2': h2, 'se': se}, index= [0])
				df_list.append(d)
		d= pd.concat(df_list)
		d.to_csv(output[0], sep= '\t', header= True, index= False)

rule heritability_META:
        'LDSC partitioned heritability.'
        input:
                '/mnt/hdd/common/pol/metaGWAS/LDscore/{pheno}.txt.sumstats.gz'
	output:
		'/mnt/hdd/common/pol/metaGWAS/LDscore/h2/{pheno}_h2.log'
	params:
		'/mnt/hdd/common/pol/metaGWAS/LDscore/h2/{pheno}_h2'
	shell:
                """
                set +eu
                source /home/pol/miniconda3/etc/profile.d/conda.sh
                conda activate ldsc
                python2 /home/pol/software/ldsc/ldsc.py \
                --h2 {input[0]} \
                --ref-ld-chr /home/pol/software/ldsc/eur_w_ld_chr/ \
                --w-ld-chr /home/pol/software/ldsc/eur_w_ld_chr/ \
                --out {params[0]}
                conda deactivate
                set -eu
                """

rule merge_h2_pheno:
	''
	input:
		expand('/mnt/hdd/common/pol/metaGWAS/LDscore/h2/{pheno}_h2.log', pheno= pheno_nms)
	output:
		'/mnt/hdd/common/pol/metaGWAS/LDscore/h2/h2_all_phenos.txt'
	run:
		df_list= list()
                for infile in input:
                        with open(infile, 'r') as f:
                                lines= [line.strip() for line in f if line.startswith('Total Observed')]
                                h2= float(lines[0].split(' ')[4])
                                se= float(lines[0].split('(')[1].replace(')', ''))
                                pheno= infile.split('/')[8].replace('_h2.log', '')
                                d= pd.DataFrame({'pheno': pheno, 'h2': h2, 'se': se}, index= [0])
                                df_list.append(d)
		d= pd.concat(df_list)
                d.to_csv(output[0], sep= '\t', header= True, index= False)


rule prepare_LD_score_meta_allPTD_NLB:
	''
	input:
		'/home/pol/software/ldsc/allCHR_eur_w_ld_chr/all_chr_eur_w_ld.txt',
		'/mnt/hdd/common/pol/metaGWAS/sumstats/META/NLB/meta_allPTD_{PTD_metas}_1.txt'
	output:
		temp('/mnt/hdd/common/pol/metaGWAS/LDscore/NLB/ldsc_{PTD_metas}.txt')
	threads: 3
	run:
		x= pd.read_csv(input[0], sep= '\t', header= 0)
		d= pd.read_csv(input[1], sep= '\t', header= 0)
		d= d.loc[(d.TOTALSAMPLESIZE> (d['TOTALSAMPLESIZE'].max())/ 2), :]
		d[['CHR', 'POS', 'REF', 'EFF', 'INDELS']]= d['MarkerName'].str.split(':', expand= True)
                d['CHR']= np.where(d['CHR']== 'X', '23', d['CHR'])
		d['POS']= d['POS'].astype(str).astype(int)
		d['CHR']= d['CHR'].astype(str).astype(int)
                d.dropna(axis= 0, inplace= True)
                d= pd.merge(d, x[['CHR', 'SNP', 'BP']], left_on= ['CHR', 'POS'], right_on= ['CHR', 'BP'])
		print(d.head())
		d= d.loc[~((d.CHR==6) & (d.POS >28477797) & (d.POS< 33448354)), :]
                d['Allele1']= d['Allele1'].str.upper()
		d['Allele2']= d['Allele2'].str.upper()
		d= d[['CHR', 'POS', 'SNP', 'Allele1', 'Allele2', 'TOTALSAMPLESIZE', 'Freq1', 'Effect', 'StdErr', 'P-value']]
		d.columns= ['CHR', 'POS', 'SNP', 'A1', 'A2', 'N', 'EAF', 'BETA', 'SE', 'pvalue']
		d.drop_duplicates(['CHR', 'POS', 'A1', 'A2'], keep= 'first', inplace= True)
                d.to_csv(output[0], sep= '\t', header= True, index= False, columns= ['SNP', 'CHR', 'POS', 'N', 'A2', 'A1', 'BETA', 'SE', 'pvalue'])

rule munge_LDSC_meta_PTD_NLB:
        'Format sumstats according to LDSC.'
        input:
                '/mnt/hdd/common/pol/metaGWAS/LDscore/NLB/ldsc_{PTD_metas}.txt'
        output:
                '/mnt/hdd/common/pol/metaGWAS/LDscore/NLB/{PTD_metas}.txt.sumstats.gz'
        params:
                '/mnt/hdd/common/pol/metaGWAS/LDscore/NLB/{PTD_metas}.txt'
        conda:
                '/home/pol/software/ldsc/environment.yml'
        shell:
                """
                set +eu
                source /home/pol/miniconda3/etc/profile.d/conda.sh
                conda activate ldsc
                python2 /home/pol/software/ldsc/munge_sumstats.py \
                --merge-alleles /home/pol/software/ldsc/w_hm3.snplist \
                --out {params[0]} \
                --sumstats {input[0]} \
                --chunksize 500000
                conda deactivate
                set -eu
                """


rule Genetic_correlation_repr_pheno_PTD_NLB:
        ''
        input:
                '/mnt/hdd/common/pol/metaGWAS/LDscore/NLB/{PTD_metas}.txt.sumstats.gz',
                expand('/mnt/hdd/common/pol/metaGWAS/repr_phenos/LDSC/{repr_pheno}.txt.sumstats.gz', repr_pheno= repr_pheno_nms)
        output:
                '/mnt/hdd/common/pol/metaGWAS/repr_phenos/LDSC/NLB/results/{PTD_metas}_rg.log'
        params:
                '/mnt/hdd/common/pol/metaGWAS/repr_phenos/LDSC/NLB/results/'
        run:
                allfiles= [infile for infile in input if wildcards.PTD_metas not in infile]
                allfiles= ','.join(allfiles)
                outfile= params[0] + wildcards.PTD_metas + '_rg'
                infile= input[0]
                shell("""
                set +eu
                source /home/pol/miniconda3/etc/profile.d/conda.sh
                conda activate ldsc
                python2 /home/pol/software/ldsc/ldsc.py \
                --rg {infile},{allfiles} \
                --ref-ld-chr /home/pol/software/ldsc/eur_w_ld_chr/ \
                --w-ld-chr /home/pol/software/ldsc/eur_w_ld_chr/ \
                --out {outfile}
                conda deactivate
                set -eu
                """)

rule format_RG_repr_pheno_PTD_NLB:
	''
	input:
		expand('/mnt/hdd/common/pol/metaGWAS/repr_phenos/LDSC/NLB/results/{PTD_metas}_rg.log', PTD_metas= ['single_pregnancy', 'all_pregnancies'])
	output:
		'/mnt/hdd/common/pol/metaGWAS/repr_phenos/LDSC/NLB/results/rg_temp.txt'
	run:
		with open(input[0], 'r') as f:
			x= f.readlines()
		x= x[x.index('Summary of Genetic Correlation Results\n')+1:-3]
		with open(output[0], 'w') as f:
			f.write(''.join(x))
		with open(input[1], 'r') as f:
			x= f.readlines()
		x= x[x.index('Summary of Genetic Correlation Results\n')+2:-3]
		with open(output[0], 'a') as f:
			f.write(''.join(x))


rule Genetic_correlation_meta_big_cohorts:
	''
	input:
		'/mnt/hdd/common/pol/metaGWAS/LDscore/individual_cohorts/{big5}.txt.sumstats.gz',
		expand('/mnt/hdd/common/pol/metaGWAS/LDscore/individual_cohorts/allPTD/{big5_allPTD}_allPTD.txt.sumstats.gz', big5_allPTD= big5_nms_allPTD)
	output:
		'/mnt/hdd/common/pol/metaGWAS/LDscore/big5/RG/{big5}_rg.log'
#       conda:
#               '/home/pol/software/ldsc/environment.yml'
	params:
		'/mnt/hdd/common/pol/metaGWAS/LDscore/big5/RG/{big5}_rg'
	run:
		allfiles= [infile for infile in input if 'individual_cohorts/' + wildcards.big5 not in infile]
		allfiles= ','.join(allfiles)
		print(allfiles)
		outfile= input[0].replace('.txt.sumstats.gz', '_rg')
		infile= input[0]
		shell("""
		set +eu
		source /home/pol/miniconda3/etc/profile.d/conda.sh
		conda activate ldsc
		python2 /home/pol/software/ldsc/ldsc.py \
		--rg {infile},{allfiles} \
		--ref-ld-chr /home/pol/software/ldsc/eur_w_ld_chr/ \
		--w-ld-chr /home/pol/software/ldsc/eur_w_ld_chr/ \
		--out {params[0]}
		conda deactivate
		set -eu
		""")

rule format_RG_PTD_GA_big:
	''
	input:
		expand('/mnt/hdd/common/pol/metaGWAS/LDscore/big5/RG/{big5}_rg.log', big5= big5_nms)
	output:
		'/mnt/hdd/common/pol/metaGWAS/LDScore/big5/RG/results/rp.txt'
	run:
		for i in range(len(input)):
			with open(input[i], 'r') as f:
				x= f.readlines()
			if i== 0: 
				x= x[x.index('Summary of Genetic Correlation Results\n')+1:-3]
				with open(output[0], 'w') as f:
					f.write(''.join(x))
			else:
				x= x[x.index('Summary of Genetic Correlation Results\n')+2:-3]
				with open(output[0], 'a') as f:
					f.write(''.join(x))

rule format_meta_big5:
	''
	input:
		'/mnt/hdd/common/pol/metaGWAS/sumstats/META/big5/meta_{two_pheno}_1.txt',
		'/mnt/hdd/common/pol/metaGWAS/processed_data/dbSNP153.txt'
	output:
		'/mnt/hdd/common/pol/metaGWAS/sumstats/META/big5/final/big5_{two_pheno}.txt.gz'
	run:
		d= pd.read_csv(input[0], sep= '\t', header= 0)
		d['Allele1']= d['Allele1'].str.upper()
		d['Allele2']= d['Allele2'].str.upper()
		d= d.loc[(d.TOTALSAMPLESIZE> (d['TOTALSAMPLESIZE'].max())/ 2), :]
		d[['CHR', 'POS', 'REF','EFF', 'SNP']]= d['MarkerName'].str.split(':', expand= True)
		d['CHR']= d['CHR'].astype(str).astype(int)
		d['POS']= d['POS'].astype(str).astype(int)
		d= d[['CHR', 'POS', 'Allele1', 'Allele2', 'TOTALSAMPLESIZE', 'Freq1', 'Effect', 'StdErr', 'P-value']]
		d.columns= ['CHR', 'POS', 'EFF', 'REF', 'TOTALSAMPLESIZE', 'EAF', 'BETA', 'SE', 'pvalue']
		d['BETA']=np.where(d.REF > d.EFF, -1* d.BETA, d.BETA)
		d['EAF']= np.where(d.REF > d.EFF, 1 - d.EAF, d.EAF)
		d['CHR']= d['CHR'].astype(str).astype(int)
		d['POS']= d['POS'].astype(str).astype(int)
		d['pvalue']= d['pvalue'].astype(str).astype(float)
		d.loc[d.REF > d.EFF, ['REF', 'EFF']] = d.loc[d.REF > d.EFF, ['EFF', 'REF']].values
		d['ID']= d.CHR.astype(int).astype(str) + ':' + d.POS.astype(int).astype(str) + ':' + d.REF + ':' + d.EFF
		d= d.loc[((d.pvalue>0) & (d.pvalue <1)), :]
		rs= pd.read_csv(input[1], sep= '\t', header=0)
		rs.columns= ['ID', 'RSID']
                d= pd.merge(d, rs, on= 'ID', how= 'left')
		d.to_csv(output[0], sep= '\t', header= True, index= False, compression= 'gzip')

rule prepare_LD_score_meta_big5:
        ''
        input:
                '/home/pol/software/ldsc/allCHR_eur_w_ld_chr/all_chr_eur_w_ld.txt',
                '/mnt/hdd/common/pol/metaGWAS/sumstats/META/big5/final/big5_{two_pheno}.txt.gz'
        output:
                temp('/mnt/hdd/common/pol/metaGWAS/LDscore/big5/two_pheno/ldsc_{two_pheno}.txt')
        threads: 3
        run:
                x= pd.read_csv(input[0], sep= '\t', header= 0)
                d= pd.read_csv(input[1], sep= '\t', header= 0)
                d['CHR']= np.where(d['CHR']== 'X', '23', d['CHR'])
                d['POS']= d['POS'].astype(str).astype(int)
                d['CHR']= d['CHR'].astype(str).astype(int)
                d.dropna(axis= 0, inplace= True)
                d= pd.merge(d, x[['CHR', 'SNP', 'BP']], left_on= ['CHR', 'POS'], right_on= ['CHR', 'BP'])
                d= d.loc[~((d.CHR==6) & (d.POS >28477797) & (d.POS< 33448354)), :]
                d= d[['CHR', 'POS', 'RSID', 'EFF', 'REF', 'TOTALSAMPLESIZE', 'EAF', 'BETA', 'SE', 'pvalue']]
                d.columns= ['CHR', 'POS', 'SNP', 'A1', 'A2', 'N', 'EAF', 'BETA', 'SE', 'pvalue']
                d.drop_duplicates(['CHR', 'POS', 'A1', 'A2'], keep= 'first', inplace= True)
                d.to_csv(output[0], sep= '\t', header= True, index= False, columns= ['SNP', 'CHR', 'POS', 'N', 'A2', 'A1', 'BETA', 'SE', 'pvalue'])

rule munge_LDSC_meta_big5:
        'Format sumstats according to LDSC.'
        input:
                '/mnt/hdd/common/pol/metaGWAS/LDscore/big5/two_pheno/ldsc_{two_pheno}.txt'
        output:
                '/mnt/hdd/common/pol/metaGWAS/LDscore/big5/two_pheno/munged/{two_pheno}.txt.sumstats.gz'
        params:
                '/mnt/hdd/common/pol/metaGWAS/LDscore/big5/two_pheno/munged/{two_pheno}.txt'
        conda:
                '/home/pol/software/ldsc/environment.yml'
        shell:
                """
                set +eu
                source /home/pol/miniconda3/etc/profile.d/conda.sh
                conda activate ldsc
                python2 /home/pol/software/ldsc/munge_sumstats.py \
                --merge-alleles /home/pol/software/ldsc/w_hm3.snplist \
                --out {params[0]} \
                --sumstats {input[0]} \
                --chunksize 500000
                conda deactivate
                set -eu
                """

rule Genetic_correlation_two_pheno_big5:
        ''
        input:
                '/mnt/hdd/common/pol/metaGWAS/LDscore/big5/two_pheno/munged/GAraw.txt.sumstats.gz',
		'/mnt/hdd/common/pol/metaGWAS/LDscore/big5/two_pheno/munged/allPTD.txt.sumstats.gz',
        output:
                '/mnt/hdd/common/pol/metaGWAS/LDscore/big5/RG/meta/GAraw_allPTD_rg.log'
        params:
                '/mnt/hdd/common/pol/metaGWAS/LDscore/big5/RG/meta/GAraw_allPTD_rg'
        run:
                shell("""
                set +eu
                source /home/pol/miniconda3/etc/profile.d/conda.sh
                conda activate ldsc
                python2 /home/pol/software/ldsc/ldsc.py \
                --rg {input[0]},{input[1]} \
                --ref-ld-chr /home/pol/software/ldsc/eur_w_ld_chr/ \
                --w-ld-chr /home/pol/software/ldsc/eur_w_ld_chr/ \
                --out {params[0]}
                conda deactivate
                set -eu
                """)



#### Creating own annotation for LD-score regression

rule gene_set_file:
	'Create gene-set file for annotations.'
	input:
		'/mnt/hdd/common/pol/metaGWAS/references/labor-associated-DEGS.txt'
	output:
		expand('/mnt/hdd/common/pol/metaGWAS/LDscore/own_annot/gene_sets/{cell_types}.txt', cell_types= cell_types_names)
	params:
		'/mnt/hdd/common/pol/metaGWAS/LDscore/own_annot/gene_sets/'
	run:
		d= pd.read_table(input[0], sep= '\t', header= 0)
		d['kbid']= d.kbid.str.split('.', expand= True)[0]
		d['Cell_type']= d.Cell_type.str.replace(' ', '-')
		for k, g in d[d['Cell_type'].isin(set(d.Cell_type))].groupby('Cell_type'):
			g.to_csv(params[0] + k + '.txt', header= False, sep= '\t', columns= ['kbid'], index= False)
		d.drop_duplicates('kbid', inplace= True, keep= 'first')
		d.to_csv(output[-1], sep= '\t', header= False, index= False, columns= ['kbid'])
		

rule annotation_file:
	'Create annotation file using LD-score scripts.'
	input:
		'/mnt/hdd/common/pol/metaGWAS/LDscore/own_annot/gene_sets/{cell_types}.txt',
		'/home/pol/software/ldsc/resources/ENSG_coord.txt',
		'/home/pol/software/ldsc/1000G_EUR_Phase3_plink/1000G.EUR.QC.{auto_CHR}.bim'
	output:
		'/mnt/hdd/common/pol/metaGWAS/LDscore/own_annot/labor_degs/{cell_types}.{auto_CHR}.annot.gz'
	run:
		shell("""
		set +eu
                source /home/pol/miniconda3/etc/profile.d/conda.sh
                conda activate ldsc
                python2 /home/pol/software/ldsc/make_annot.py \
		--gene-set-file {input[0]} \
		--gene-coord-file {input[1]} \
		--windowsize 100000 \
		--bimfile {input[2]} \
		--annot-file {output[0]}
		set -eu
		""")

rule calculate_LD_scores:
	'Compute LD scores for the annotations generated in previous rule.'
	input:
		'/mnt/hdd/common/pol/metaGWAS/LDscore/own_annot/labor_degs/{cell_types}.{auto_CHR}.annot.gz',
		'/home/pol/software/ldsc/resources/hapmap3_snps/hm.{auto_CHR}.snp',
		expand('/home/pol/software/ldsc/1000G_EUR_Phase3_plink/1000G.EUR.QC.{{auto_CHR}}.{ext}', ext= ['bed', 'bim', 'fam'])
	output:
		'/mnt/hdd/common/pol/metaGWAS/LDscore/own_annot/labor_degs/{cell_types}.{auto_CHR}.l2.ldscore.gz',
		'/mnt/hdd/common/pol/metaGWAS/LDscore/own_annot/labor_degs/{cell_types}.{auto_CHR}.l2.M_5_50'
	params:
		'/home/pol/software/ldsc/1000G_EUR_Phase3_plink/1000G.EUR.QC.{auto_CHR}',
		'/mnt/hdd/common/pol/metaGWAS/LDscore/own_annot/labor_degs/{cell_types}.{auto_CHR}'
	run:
		shell("""
		set +eu
                source /home/pol/miniconda3/etc/profile.d/conda.sh
                conda activate ldsc
		python2 /home/pol/software/ldsc/ldsc.py \
		--l2 \
		--bfile {params[0]} \
		--ld-wind-cm 1 \
		--annot {input[0]} \
		--out {params[1]} \
		--print-snps {input[1]} \
		--thin-annot
		""")

rule partitioned_heritability_own_annotations:
	'LDSC partitioned heritability.'
	input:
		'/mnt/hdd/common/pol/metaGWAS/LDscore/{pheno}.txt.sumstats.gz',
		expand('/mnt/hdd/common/pol/metaGWAS/LDscore/own_annot/labor_degs/{{cell_types}}.{auto_CHR}.l2.ldscore.gz', auto_CHR= auto_CHR_nms),
		expand('/mnt/hdd/common/pol/metaGWAS/LDscore/own_annot/labor_degs/{{cell_types}}.{auto_CHR}.l2.M_5_50', auto_CHR= auto_CHR_nms) , 
		expand('/mnt/hdd/common/pol/metaGWAS/LDscore/own_annot/labor_degs/{{cell_types}}.{auto_CHR}.annot.gz', auto_CHR= auto_CHR_nms)
	output:
		'/mnt/hdd/common/pol/metaGWAS/LDscore/own_annot/results/{pheno}_{cell_types}.log',
		'/mnt/hdd/common/pol/metaGWAS/LDscore/own_annot/results/{pheno}_{cell_types}.results'
	params:
		'/mnt/hdd/common/pol/metaGWAS/LDscore/own_annot/results/{pheno}_{cell_types}',
		'/mnt/hdd/common/pol/metaGWAS/LDscore/own_annot/labor_degs/{cell_types}'
	wildcard_constraints:
		pheno= '|'.join(pheno_nms)
	threads: 2
	shell:
                '''
                set +eu
                source /home/pol/miniconda3/etc/profile.d/conda.sh
                conda activate ldsc
                python2 /home/pol/software/ldsc/ldsc.py \
                --h2 {input[0]}\
                --ref-ld-chr /home/pol/software/ldsc/baseline/baseline/baselineLD.,{params[1]}. \
                --w-ld-chr /home/pol/software/ldsc/baseline/weights_hm3_no_hla/weights.\
                --overlap-annot \
                --frqfile-chr /home/pol/software/ldsc/baseline/1000G_Phase3_frq/1000G.EUR.QC. \
                --out {params[0]} \
		--thin-annot
                conda deactivate
                set -eu
                '''

rule intermediary_file_merging_enrichment:
	''
	input:
		'/mnt/hdd/common/pol/metaGWAS/LDscore/own_annot/results/{pheno}_{cell_types}.results',
		'/mnt/hdd/common/pol/metaGWAS/LDscore/own_annot/gene_sets/{cell_types}.txt'
	output:
		temp('/mnt/hdd/common/pol/metaGWAS/LDscore/own_annot/results/temp/{pheno}/{cell_types}.txt')
	run:
		d= pd.read_csv(input[0], sep= '\t', header= 0)
		d= d.loc[d.Category== 'L2_1', :]
		x= pd.read_csv(input[1], sep= '\t', header= None, names= ['Gene'])
		d['n_genes']= x.shape[0]
		d['Category']= wildcards.cell_types
		d.to_csv(output[0], sep= '\t', header= True, index= False)

rule merge_partitioned_heritability:
	''
	input:
		expand('/mnt/hdd/common/pol/metaGWAS/LDscore/own_annot/results/temp/{{pheno}}/{cell_types}.txt', cell_types= cell_types_names)
	output:
		'/mnt/hdd/common/pol/metaGWAS/LDscore/own_annot/results/all/{pheno}_labor_DEGs.txt'
	shell:
		'''
		head -1 {input[0]} > {output[0]}
		tail -n +2 -q {input} >> {output[0]}
		'''

rule annotation_file_cts_control:
	'Create annotation file using LD-score scripts for control.'
	input:
		'/mnt/hdd/common/pol/metaGWAS/references/labor_associated_controls.txt',
		'/home/pol/software/ldsc/resources/ENSG_coord.txt',
		'/home/pol/software/ldsc/1000G_EUR_Phase3_plink/1000G.EUR.QC.{auto_CHR}.bim'
	output:
		'/mnt/hdd/common/pol/metaGWAS/LDscore/own_annot/controls/{auto_CHR}.annot.gz'
	wildcard_constraints:
		auto_CHR= '|'.join([str(i) for i in auto_CHR_nms])
	run:
		shell("""
                set +eu
                source /home/pol/miniconda3/etc/profile.d/conda.sh
                conda activate ldsc
                python2 /home/pol/software/ldsc/make_annot.py \
                --gene-set-file {input[0]} \
                --gene-coord-file {input[1]} \
                --windowsize 100000 \
                --bimfile {input[2]} \
                --annot-file {output[0]}
                set -eu
                """)

rule calculate_LD_scores_control_annotation:
        'Compute LD scores for the annotations generated in previous rule for control annotation.'
        input:
                '/mnt/hdd/common/pol/metaGWAS/LDscore/own_annot/controls/{auto_CHR}.annot.gz',
                '/home/pol/software/ldsc/resources/hapmap3_snps/hm.{auto_CHR}.snp',
                expand('/home/pol/software/ldsc/1000G_EUR_Phase3_plink/1000G.EUR.QC.{{auto_CHR}}.{ext}', ext= ['bed', 'bim', 'fam'])
        output:
                '/mnt/hdd/common/pol/metaGWAS/LDscore/own_annot/controls/{auto_CHR}.l2.ldscore.gz',
                '/mnt/hdd/common/pol/metaGWAS/LDscore/own_annot/controls/{auto_CHR}.l2.M_5_50'
        params:
                '/home/pol/software/ldsc/1000G_EUR_Phase3_plink/1000G.EUR.QC.{auto_CHR}',
                '/mnt/hdd/common/pol/metaGWAS/LDscore/own_annot/controls/{auto_CHR}'
	wildcard_constraints:
		auto_CHR= '|'.join([str(i) for i in auto_CHR_nms])
	run:
		
                shell("""
                set +eu
                source /home/pol/miniconda3/etc/profile.d/conda.sh
                conda activate ldsc
                python2 /home/pol/software/ldsc/ldsc.py \
                --l2 \
                --bfile {params[0]} \
                --ld-wind-cm 1 \
                --annot {input[0]} \
                --out {params[1]} \
                --print-snps {input[1]} \
                --thin-annot
                """)

rule prepare_ldct_file_labor_DEG:
        'Prepare a file with two columns. The first column has a label, for example the name of the cell type in question. The second column has a comma delimited list of LD scores to include when doing the regression for that cell type.'
        input:
                expand('/mnt/hdd/common/pol/metaGWAS/LDscore/own_annot/labor_degs/{{cell_types}}.{auto_CHR}.l2.M_5_50', auto_CHR= auto_CHR_nms),
                expand('/mnt/hdd/common/pol/metaGWAS/LDscore/own_annot/labor_degs/{{cell_types}}.{auto_CHR}.annot.gz', auto_CHR= auto_CHR_nms),
                expand('/mnt/hdd/common/pol/metaGWAS/LDscore/own_annot/controls/{auto_CHR}.annot.gz', auto_CHR= auto_CHR_nms),
		expand('/mnt/hdd/common/pol/metaGWAS/LDscore/own_annot/controls/{auto_CHR}.l2.ldscore.gz', auto_CHR= auto_CHR_nms),
		expand('/mnt/hdd/common/pol/metaGWAS/LDscore/own_annot/controls/{auto_CHR}.l2.M_5_50', auto_CHR= auto_CHR_nms)
        output:
                temp('/mnt/hdd/common/pol/metaGWAS/LDscore/own_annot/controls/ldcts/temp/{cell_types}.txt')
        params:
                '/mnt/hdd/common/pol/metaGWAS/LDscore/own_annot/labor_degs/{cell_types}.',
                '/mnt/hdd/common/pol/metaGWAS/LDscore/own_annot/controls/'
        run:
                if wildcards.cell_types!= 'overall':
                        d= pd.DataFrame({'V1': [wildcards.cell_types], 'V2': ','.join(params)})
                        d.to_csv(output[0], sep= '\t', header= False, index= False)
                else:
                        open(output[0], 'a').close()

rule merge_ldcts:
        ''
        input:
                expand('/mnt/hdd/common/pol/metaGWAS/LDscore/own_annot/controls/ldcts/temp/{cell_types}.txt', cell_types= cell_types_names)
        output:
                '/mnt/hdd/common/pol/metaGWAS/LDscore/own_annot/controls/ldcts/labor_DEG.ldcts'
        shell:
                'cat {input} > {output[0]}'

rule partitioned_heritability_own_annotations_cts:
        'LDSC partitioned heritability.'
        input:
                '/mnt/hdd/common/pol/metaGWAS/LDscore/{pheno}.txt.sumstats.gz',
		'/mnt/hdd/common/pol/metaGWAS/LDscore/own_annot/controls/ldcts/labor_DEG.ldcts',
                expand('/mnt/hdd/common/pol/metaGWAS/LDscore/own_annot/labor_degs/{cell_types}.{auto_CHR}.l2.ldscore.gz', auto_CHR= auto_CHR_nms, cell_types= cell_types_names),
                expand('/mnt/hdd/common/pol/metaGWAS/LDscore/own_annot/labor_degs/{cell_types}.{auto_CHR}.l2.M_5_50', auto_CHR= auto_CHR_nms, cell_types= cell_types_names),
                expand('/mnt/hdd/common/pol/metaGWAS/LDscore/own_annot/labor_degs/{cell_types}.{auto_CHR}.annot.gz', auto_CHR= auto_CHR_nms, cell_types= cell_types_names)
        output:
                '/mnt/hdd/common/pol/metaGWAS/LDscore/own_annot/results/cts/{pheno}.log',
                '/mnt/hdd/common/pol/metaGWAS/LDscore/own_annot/results/cts/{pheno}.results.txt'
        params:
                '/mnt/hdd/common/pol/metaGWAS/LDscore/own_annot/results/cts/{pheno}',
        wildcard_constraints:
                pheno= '|'.join(pheno_nms)
        threads: 2
        shell:
                '''
                set +eu
                source /home/pol/miniconda3/etc/profile.d/conda.sh
                conda activate ldsc
                python2 /home/pol/software/ldsc/ldsc.py \
                --h2-cts {input[0]}\
                --ref-ld-chr /home/pol/software/ldsc/baseline/baseline/baselineLD. \
		--ref-ld-chr-cts {input[1]} \
                --w-ld-chr /home/pol/software/ldsc/baseline/weights_hm3_no_hla/weights.\
                --overlap-annot \
                --frqfile-chr /home/pol/software/ldsc/baseline/1000G_Phase3_frq/1000G.EUR.QC. \
                --out {params[0]} \
                --thin-annot
                conda deactivate
                set -eu
                '''

